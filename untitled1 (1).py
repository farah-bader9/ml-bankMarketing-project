# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gmWu4m2JdvYEh1uZ8VnAlRh6RnvdH7iW
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
path = '/content/drive/MyDrive/bank marketing/bank.csv'
data = pd.read_csv(path, sep=';')
data.head()

print(data.columns)

# --- Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ ---
import pandas as pd

path = '/content/drive/MyDrive/bank marketing/bank.csv'

# Ù‡Ù†Ø§ ØºÙŠØ±Ù†Ø§ Ø§Ù„ÙØ§ØµÙ„ Ù…Ù† ';' Ø¥Ù„Ù‰ ',' Ù„Ø£Ù†Ù‡ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…ÙØµÙˆÙ„ Ø¨ÙÙˆØ§ØµÙ„ Ù…Ùˆ ÙØ§ØµÙ„Ø© Ù…Ù†Ù‚ÙˆØ·Ø©
data = pd.read_csv(path)

# --- ÙØµÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ---
X = data.drop('deposit', axis=1)
y = data['deposit']

# --- ØªØ±Ù…ÙŠØ² y ---
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# --- Ø§Ù„ØªØ£ÙƒØ¯ ---
print(X.head())
print(y[:5])

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("âœ… ØªÙ… Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­")
print(X_train.shape, X_test.shape)
print(y_train.shape, y_test.shape)

# Ù†Ø­ÙˆÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
for column in X.columns:
    if X[column].dtype == 'object':
        le = LabelEncoder()
        X[column] = le.fit_transform(X[column])

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# ØªÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
y_pred = model.predict(X_test)

# ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡
print("âœ… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:", accuracy_score(y_test, y_pred))
print("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\n", classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Ø­Ø³Ø§Ø¨ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
cm = confusion_matrix(y_test, y_pred)

# Ø¹Ø±Ø¶ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

from sklearn.neighbors import KNeighborsClassifier

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_knn = KNeighborsClassifier(n_neighbors=5)

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_knn.fit(X_train, y_train)

# Ø¹Ù…Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred_knn = model_knn.predict(X_test)

# Ø¹Ø±Ø¶ Ø§Ù„Ø¯Ù‚Ø© ÙˆØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ
from sklearn.metrics import accuracy_score, classification_report
print("KNN Accuracy:", accuracy_score(y_test, y_pred_knn))
print("KNN Classification Report:\n", classification_report(y_test, y_pred_knn))

import pandas as pd

# Ø­ÙØ¸ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
pd.DataFrame(y_pred_knn).to_csv("predictions_KNN_model.csv", index=False)

from sklearn.svm import SVC

# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_svm = SVC()
model_svm.fit(X_train, y_train)

# Ø¹Ù…Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred_svm = model_svm.predict(X_test)

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
from sklearn.metrics import accuracy_score, classification_report
print("SVM Accuracy:", accuracy_score(y_test, y_pred_svm))
print("SVM Classification Report:\n", classification_report(y_test, y_pred_svm))

pd.DataFrame(y_pred_svm).to_csv("predictions_SVM_model.csv", index=False)

from sklearn.naive_bayes import GaussianNB

# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_nb = GaussianNB()
model_nb.fit(X_train, y_train)

# Ø¹Ù…Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred_nb = model_nb.predict(X_test)

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
from sklearn.metrics import accuracy_score, classification_report
print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print("Naive Bayes Classification Report:\n", classification_report(y_test, y_pred_nb))

pd.DataFrame(y_pred_nb).to_csv("predictions_NaiveBayes_model.csv", index=False)

from sklearn.ensemble import RandomForestClassifier

# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_rf = RandomForestClassifier()
model_rf.fit(X_train, y_train)

# Ø¹Ù…Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred_rf = model_rf.predict(X_test)

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
from sklearn.metrics import accuracy_score, classification_report
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Random Forest Classification Report:\n", classification_report(y_test, y_pred_rf))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Ø­Ø³Ø§Ø¨ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
cm_rf = confusion_matrix(y_test, y_pred_rf)

# Ø¹Ø±Ø¶ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf)
disp_rf.plot()

pd.DataFrame(y_pred_rf).to_csv("predictions_RF_model.csv", index=False)

from sklearn.neural_network import MLPClassifier

# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)
model_ann.fit(X_train, y_train)

# Ø¹Ù…Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤
y_pred_ann = model_ann.predict(X_test)

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
from sklearn.metrics import accuracy_score, classification_report
print("ANN Accuracy:", accuracy_score(y_test, y_pred_ann))
print("ANN Classification Report:\n", classification_report(y_test, y_pred_ann))

pd.DataFrame(y_pred_ann).to_csv("predictions_ANN_model.csv", index=False)

from sklearn.linear_model import LinearRegression

# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)

# Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù‚ÙŠÙ… (Ø±Ø­ ØªØ·Ù„Ø¹ ÙƒØ³ÙˆØ±)
y_pred_lr = model_lr.predict(X_test)

# Ù†Ø­ÙˆÙ„Ù‡Ø§ Ø¥Ù„Ù‰ ØªØµÙ†ÙŠÙ: Ø£ÙŠ Ù‚ÙŠÙ…Ø© Ø£ÙƒØ¨Ø± Ù…Ù† Ø£Ùˆ ØªØ³Ø§ÙˆÙŠ 0.5 ØªØµÙŠØ± 1ØŒ ØºÙŠØ± ÙƒØ°Ø§ ØªØµÙŠØ± 0
y_pred_lr_class = [1 if i >= 0.5 else 0 for i in y_pred_lr]

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
from sklearn.metrics import accuracy_score, classification_report
print("Linear Regression Accuracy:", accuracy_score(y_test, y_pred_lr_class))
print("Linear Regression Classification Report:\n", classification_report(y_test, y_pred_lr_class))

pd.DataFrame(y_pred_lr_class).to_csv("predictions_LinearRegression_model.csv", index=False)

pd.DataFrame(X_train).to_csv("X.csv", index=False)
pd.DataFrame(X_test).to_csv("X_test.csv", index=False)
pd.DataFrame(y_train).to_csv("Y.csv", index=False)
pd.DataFrame(y_test).to_csv("Y_test.csv", index=False)

from sklearn.metrics import accuracy_score, classification_report

print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred))
print("Decision Tree Classification Report:\n", classification_report(y_test, y_pred))

pd.DataFrame(y_pred).to_csv("predictions_DecisionTree_model.csv", index=False)

import seaborn as sns
import matplotlib.pyplot as plt

# Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ø¯Ù‚Ø©
model_names = ['Decision Tree', 'KNN', 'SVM', 'Naive Bayes', 'Random Forest', 'ANN', 'Linear Regression']
accuracies = [0.78, 0.75, 0.72, 0.75, 0.83, 0.69, 0.78]

# Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø§ØªØ§ ÙØ±ÙŠÙ…
import pandas as pd
df_results = pd.DataFrame({'Model': model_names, 'Accuracy': accuracies})

# Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Seaborn
plt.figure(figsize=(10,6))
sns.barplot(x='Model', y='Accuracy', data=df_results, palette='Blues_d')
plt.title('Model Accuracy Comparison', fontsize=16)
plt.ylim(0.6, 0.9)
plt.xticks(rotation=45)
plt.show()